import numpy as np
import scipy
import matplotlib.pyplot as plt
import fbpca

from scipy import sparse
from sklearn.utils.extmath import randomized_svd


def create_data_matrix_from_video(clip, k=5, scale=50):
    return np.vstack([scipy.misc.imresize(rgb2gray(clip.get_frame(i / float(k))).astype(int),
                                          scale).flatten() for i in range(k * int(clip.duration))]).T


def rgb2gray(rgb):
    return np.dot(rgb[..., :3], [0.299, 0.587, 0.114])


def plt_images(M, A, E, index_array, dims, filename=None):
    f = plt.figure(figsize=(15, 10))
    r = len(index_array)
    pics = r * 3
    for k, i in enumerate(index_array):
        for j, mat in enumerate([M, A, E]):
            sp = f.add_sublpot(r, 3, 3 * k + j + 1)
            sp.axis('Off')
            pixels = mat[:, i]
            if isinstance(pixels, scipy.sparse.csr_matrix):
                pixels = pixels.todense()
            plt.imshow(np.reshape(pixels, dims), cmap='gray')
            plt.show()
    return f


def plots(ims, dims, figsize=(15, 20), rows=1, interp=False, titles=None):
    if type(ims[0]) is np.ndarray:
        ims = np.array(ims)
    f = plt.figure(figsize=figsize)
    for i in range(len(ims)):
        sp = f.add_subplot(rows, len(ims) // rows, i + 1)
        sp.axis('Off')
        plt.imshow(np.reshape(ims[i], dims), cmap="gray")
        plt.show()


TOL = 1e-9
MAX_ITERS = 3


def converged(Z, d_norm):
    err = np.linalg.norm(Z, 'fro') / d_norm
    print('error:: ', err)
    return err < TOL


def shrink(M, tau):
    S = np.abs(M) - tau
    return np.sign(M) * np.where(S > 0, S, 0)


def _svd(M, rank):
    return fbpca.pca(M, k=min(rank, np.min(M.shape)), raw=True)


def norm_op(M):
    return _svd(M, 1)[1][0]


def svd_reconstruct(M, rank, min_sv):
    u, s, v = _svd(M, rank)
    s -= min_sv
    nnz = (s > 0).sum()
    return u[:,:nnz] @ np.diag(s[:nnz]) @ v[:nnz], nnz


def pcp(X, maxiter=10, k=10):  # refactored
    m, n = X.shape
    trans = m < n
    if trans: X = X.T; m, n = X.shape

    lamda = 1 / np.sqrt(m)
    op_norm = norm_op(X)
    Y = np.copy(X) / max(op_norm, np.linalg.norm(X, np.inf) / lamda)
    mu = k * 1.25 / op_norm;
    mu_bar = mu * 1e7;
    rho = k * 1.5

    d_norm = np.linalg.norm(X, 'fro')
    L = np.zeros_like(X);
    sv = 1

    examples = []

    for i in range(maxiter):
        print("rank sv:", sv)
        X2 = X + Y / mu

        # update estimate of Sparse Matrix by "shrinking/truncating": original - low-rank
        S = shrink(X2 - L, lamda / mu)

        # update estimate of Low-rank Matrix by doing truncated SVD of rank sv & reconstructing.
        # count of singular values > 1/mu is returned as svp
        L, svp = svd_reconstruct(X2 - S, sv, 1 / mu)

        # If svp < sv, you are already calculating enough singular values.
        # If not, add 20% (in this case 240) to sv
        sv = svp + (1 if svp < sv else round(0.05 * n))

        # residual
        Z = X - L - S
        Y += mu * Z;
        mu *= rho

        examples.extend([S[140, :], L[140, :]])

        if m > mu_bar: m = mu_bar
        if converged(Z, d_norm): break

    if trans: L = L.T; S = S.T
    return L, S, examples
